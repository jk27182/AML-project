{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "                                                                           \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import joblib\n",
    "\n",
    "import sklearn.metrics as skmetrics\n",
    "\n",
    "from nam.trainer import Trainer\n",
    "from nam.data import NAMDataset\n",
    "from nam.config import defaults\n",
    "from nam.data import FoldedDataset\n",
    "from nam.models import NAM\n",
    "from nam.models import get_num_units\n",
    "from nam.trainer import LitNAM\n",
    "from nam.types import Config\n",
    "from nam.utils import parse_args\n",
    "from nam.utils import plot_mean_feature_importance\n",
    "from nam.utils import plot_nams\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/all_data.pickle', 'rb') as file:\n",
    "    all_data = pickle.load(file)\n",
    "\n",
    "orig_characteristics = all_data['OrigCharacteristics.dta']\n",
    "orig_characteristics_columns = [\n",
    "    'type',\n",
    "    'CutoffLTV',\n",
    "    'CutoffDSCR',\n",
    "    'CutoffCpn',\n",
    "    'log_bal',\n",
    "    'fixed',\n",
    "    'buildingage',\n",
    "    'CutoffOcc',\n",
    "    'quarter_type',\n",
    "    'AmortType',\n",
    "    'Size',\n",
    "    'OVER_w',\n",
    "    'past_over',\n",
    "    'high_overstatement2',\n",
    "    'Distress'\n",
    "]\n",
    "orig_data = orig_characteristics[orig_characteristics_columns]\n",
    "target_col = 'Distress'\n",
    "orig_data_with_dummies = pd.get_dummies(\n",
    "    orig_data,\n",
    "    columns=[\n",
    "        'AmortType',\n",
    "        'type',\n",
    "    ]\n",
    ")\n",
    "clean_data = orig_data_with_dummies[\n",
    "    orig_data_with_dummies.notna().all(axis=1)\n",
    "]\n",
    "\n",
    "dummy_cols = [col for col, dtype in clean_data.dtypes.items() if dtype == bool]\n",
    "for dummy_col in dummy_cols:\n",
    "    clean_data[dummy_col] = clean_data[dummy_col].map({True: 1, False:0})\n",
    "\n",
    "# Percentage of clean data from whole dataset\n",
    "print('percentage of clean data and all data ', len(clean_data) / len(orig_data_with_dummies))\n",
    "\n",
    "y = clean_data[target_col]\n",
    "X = clean_data.drop(columns=target_col)\n",
    "feature_cols = X.columns\n",
    "X['Distress'] = y\n",
    "sample_size = len(y)\n",
    "print('sample size ', sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load hyperparameters for NAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/best_params_nam_maximize.joblib', 'rb') as file:\n",
    "    hyper_params = joblib.load(file)['params']\n",
    "\n",
    "config = defaults()\n",
    "config.val_size = 0.0\n",
    "config.test_size = 0.0\n",
    "config.num_workers = 4\n",
    "config.wandb = False\n",
    "config.update(**hyper_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAM training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nam_dataset = NAMDataset(\n",
    "    config,\n",
    "    data_path=X,\n",
    "    features_columns=feature_cols,\n",
    "    targets_column='Distress',\n",
    ")\n",
    "nam_model = NAM(\n",
    "    config=config,\n",
    "    name='Final_NAM',\n",
    "    num_inputs=len(nam_dataset[0][0]),\n",
    "    num_units=get_num_units(config, nam_dataset.features)\n",
    ")\n",
    "litnam = LitNAM(config, nam_model)\n",
    "trainer = pl.Trainer()\n",
    "\n",
    "data_loaders = nam_dataset.train_dataloaders()\n",
    "for run, (train_loader, val_loader) in enumerate(data_loaders):\n",
    "    print('run ', run)\n",
    "    tb_logger = TensorBoardLogger(\n",
    "        save_dir=config.logdir,\n",
    "        name=f'{nam_model.name}',\n",
    "        version=f'run{run + 1}')\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        filename=tb_logger.log_dir + \"/{epoch:02d}-{val_loss:.4f}\",\n",
    "        monitor='val_loss',\n",
    "        save_top_k=config.save_top_k,\n",
    "        mode='max'\n",
    "    )\n",
    "    trainer = pl.Trainer(\n",
    "        logger=tb_logger,\n",
    "        max_epochs=config.num_epochs,\n",
    "        callbacks=checkpoint_callback,\n",
    "        log_every_n_steps=5\n",
    "    )\n",
    "    trainer.fit(\n",
    "        litnam,\n",
    "        train_dataloaders=train_loader,\n",
    "        val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = litnam.model\n",
    "X.reset_index(drop=True, inplace=True)\n",
    "sample_size = len(X)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad() as grad:\n",
    "    logits, fnns = model(torch.tensor(X.loc[:sample_size, feature_cols].values, dtype=torch.double))\n",
    "    targets = torch.tensor(X.loc[:sample_size, 'Distress'].values, dtype=torch.double) \n",
    "\n",
    "y = targets.numpy()\n",
    "pred = logits.numpy()\n",
    "\n",
    "fpr, tpr, thresholds = skmetrics.roc_curve(y, pred)\n",
    "roc_auc = skmetrics.auc(fpr, tpr)\n",
    "display = skmetrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
    "                                  estimator_name='ROC NAM')\n",
    "sns.set_style('darkgrid')\n",
    "display.plot()\n",
    "display.line_.set_color('#F09135') \n",
    "fig = display.figure_\n",
    "ax = display.ax_\n",
    "# plot diagonal\n",
    "ax.plot(np.linspace(0,1,2),np.linspace(0,1,2), linewidth=.8, linestyle='--', color='#00007B')\n",
    "\n",
    "ax.set_facecolor('#E5EDF6')\n",
    "fig.savefig('../plots/NAM_ROC.png', format='png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_mean_feature_importance(litnam.model, nam_dataset, width=0.4)\n",
    "fig.savefig('../plots/NAM_FeatureImportance.png', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_nams(litnam.model, nam_dataset, num_cols=4)\n",
    "fig.savefig('../plots/NAM_FeatureContributions.png', format='png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
