\documentclass{article}

% Language setting
% Replace `english' with e.g. `spanish' to change the document language
\usepackage[english]{babel}

% Set page size and margins
% Replace `letterpaper' with `a4paper' for UK/EU standard size
\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}

\title{Advanced Machine Learning Project}
\author{Janik KÃ¶nigshofer}

\begin{document}
\maketitle

\begin{abstract}
Your abstract.
\end{abstract}

\section{Introduction}
The following paper presents my findings from the project that I conducted in the scope of the lecture 'Advanced Machine Learning'.
I extended the experiments conducted by the authors of \cite{CMBS-Paper}, which used linear and instrumental variable regression techniques with different levels of fixed effects by using explainable artificial intelligence (XAI) on a selected group of experiments.
The goal is show that XAI is not only a powerful framework to conduct predctions, but is also a valid alternative to common approaches from econometrics in terms of explainability.
The scope of this project is restricted to the experiments that were conducted 
First, I will summarize the underlying paper \cite{CMBS-Paper}. Furthermore, I will introduce my approach to classify if a cloan is \textcolor{red}{overstated or not} using XAI, giving an overview of the three algorithms that I used in this context. After that, I will present the results of the three approaches, contrast them and also validate the results.
\textcolor{red}{Finally, summarize my project by highlighting pros and cons}.


I used the conducted experiments in \cite{CMBS-Paper} as a baseline to predict the \textcolor{red}{distress of commercially mortgage-backed securites} using explainable artificial intelligence (XAI) and contrasted the corresponding results.
According to \textcolor{red}{CITATION NEEDED} financial distress is a term used to indicates a condition in which a company or individual cannot generate sufficient revenues or income, making it unable to meet or pay its financial obligations. 
%(https://www.investopedia.com/terms/f/financial_distress.asp) 
\textcolor{red}{The goal of this project was to show that XAI can be effectivly used to conduct experiments}.

\section{Literature Review}
In \cite{CMBS-Paper} Griffin and Priest presented a study to reasearch the impact of COVID-19 on commercial mortgage-backed securities (CMBS) and to identify differences in underwriting standards across originators.
Commercial mortgage-backed securites are financial instruments which allow investors to trade financial assets that are backed with housing mortgages. 
In order to achieve this, the authors analyzed data on income overstatement in CMBS 2.0 deals, and examined its relationship with loan distress and other loan characteristics.
They found that originator-specific differences in income overstatement were related to loan distress, and that pre-COVID underwriting quality played a large role in the ability of assets to withstand distress. The authors concluded that recent market stresses revealed large systemic differences in underwriting standards across originators, and that originator income overstatement was highly predictive of pre- and COVID-period loan distress.

\section{Methodical Setup}
This section presents the methodical setup of my experiments, first by shortly introducing the concept of XAI and second by introducing the theoretical background of the three algorithms that I used in my experiments.
\subsection{Explainable Artificial Intelligence}
Whilst traditional machine learning methods like deep neural networks often provide good performance, they are a black-box model, meaning without any further methods the reasoning process of a model for a decision is not easily accessible.
However, that process is crucial when the model is supposed to work in an environment in which it is not sufficient to trust that the model is tested enough and covers most corner cases.
According to \cite{Rudin2019}, there are significant advantages of using inherently interpretable methods over methods that require additional methods that try to explain the black box model.
A research field that is concerned with this is explainable artificial intelligence (XAI).
I used XAI in order to find reasonable drivers for the prediction of CMBS overstatement.
The following sections present the three methods that I used and describe the theoretical background.

\subsection{Explainable Boosting Machine}
As presented in \cite{nazemi2022interpretable} the Explainable Boosting Machine (EBM) was first proposes by \cite{nori2019interpretable} and constitutes a tree-based gradient boosting model constructed upon the foundational principles of the Generalized Additive Model (GAM), originally proposed by \cite{hastie1986generalized}. The GAM framework, characterized by its ability to capture both linear and nonlinear features, facilitates the modeling of intricate relationships between predictors and target values through learned functions. They can be represented as follows:
\begin{equation}
g(E(y)) = \beta_0 + \sum_{i=1}^{m} f_i(x_i) = \beta_0 + f_1(x_1) + f_2(x_2) + \dots + f_m(x_m)
\end{equation}
Here, \(E(y)\) signifies the expected value, \(g\) is the linking function establishing a connection between the anticipated value and explanatory variables \(x_1, \ldots, x_m\), and \(f_i\) are nonlinear smooth functions, each acquired by the model for a distinct variable. The adoption of GAMs offers the advantage of interpretable estimations and enhanced performance relative to standard linear regression due to their adeptness in addressing nonlinear associations. \cite{nazemi2022interpretable}

The EBM extends the principles of GAMs by implementing refinements to address co-linearity effects and optimize feature functions for each predictor through the incorporation of tree-based techniques. Furthermore, the EBM method excels in identifying pairwise interactions, thereby bolstering performance while preserving interpretability, as shown in \cite{lou2013accurate}. Hence, the EBM is of the following form:

\begin{equation}
g(E(y)) = \beta_0 + \sum_{i} f_i(x_i) + \sum_{i, j} f_{i,j}(x_i, x_j).
\end{equation}
Interpretability can be acquired by by examining $f_i$ or $f_{i, j}$ for the contribution of each variable or variable pair to the prediction. \cite{nazemi2022interpretable}
\subsection{Logistic Regression}
\subsection{Neural Additive Model}
Neural Additive Models, as described by \cite{nazemi2022interpretable}, was introduced by \cite{NAM-Library1}, follow a similiar approach as the EBM. They are also based on a GAM, however instead of using tree based models to fit the non-linear functions, they use neural networks. For each variable, a neural network is trained.
As the trained neural networks are the input for the GAM, according to \cite{nazemi2022interpretable}, they can be written as follows:

\begin{equation}
g(E(y)) = \beta_0 + \sum_{i=1}^{m} h_i(x_i) = \beta_0 + h_1(x_1) + h_2(x_2) + \dots + h_m(x_m),
\end{equation}
with $h_i, i \in \{1,\dots, m\}$ are the corresponding neural networks.
Similar to the EBM, the interpretability can be achieved by looking at the neural network, namely its parametrization, for a corresponding variable. \cite{nazemi2022interpretable}
\section{Experiments}
In this section I will give a short introduction into the data that I used and the methodical setup to train the three models. Furthermore, I will go into detail about the challenges that I encountered during the training process and highlight design decision in the training process.
\subsection{Experimental Setup}
Since the goal of this project is to predict wether or not a loan can be classified as 'distress', which is defined by the authors from \cite{CMBS-Paper} as a binary variable if a loan appears on a servicer's watchlist or becomes non-perfomring from April 2020 to April 2021, I started out by 
InterpretML \cite{InterpretML}, NAM library \cite{NAM-Library1, NAM-Library2}

% \begin{table}
% \centering
% \begin{tabular}{l|r}
% Item & Quantity \\\hline
% Widgets & 42 \\
% Gadgets & 13
% \end{tabular}
% \caption{\label{tab:widgets}An example table.}
% \end{table}


\section{Conclusion}

\bibliographystyle{unsrt}
\bibliography{sample}

\end{document}